<!DOCTYPE html>
<html lang="en"><head>
<script src="02_shap_files/libs/clipboard/clipboard.min.js"></script>
<script src="02_shap_files/libs/quarto-html/tabby.min.js"></script>
<script src="02_shap_files/libs/quarto-html/popper.min.js"></script>
<script src="02_shap_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="02_shap_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="02_shap_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="02_shap_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.0.36">

  <meta name="author" content="Przemysław Biecek">
  <title>Shapley values</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="02_shap_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="02_shap_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="02_shap_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="02_shap_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="02_shap_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="02_shap_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="02_shap_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="02_shap_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="02_shap_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="center">
  <h1 class="title">Shapley values</h1>
  <p class="subtitle">eXplainable AI</p>
  <p class="author">Przemysław Biecek</p>
  <p class="date">Machine Learning @ MIMUW 2022</p>
</section>

<section class="slide level2">

<p>
<img src="images/aitech.png" width="100%">
</p>
</section>
<section>
<section id="paper-of-the-day" class="title-slide slide level1 center">
<h1>Paper of the day</h1>
<div class="cell">
<style type="text/css">
.reveal {
  font-size: 24px;
  line-height: 1.6!important;
}
code {
  font-size: 18px!important;
  line-height: 1.2!important;
}
pre {
  line-height: 1.2!important;
}
</style>
</div>
</section>
<section id="a-unified-approach-to-interpreting-model-predictions" class="slide level2">
<h2>A Unified Approach to Interpreting Model Predictions</h2>
<ul>
<li>In this course, you will learn about the main methods and tools related to XAI, but also (and this may be unique) about selected papers and researchers.</li>
<li>That’s why we will start this and the next classes with a brief presentation of a high-impact article from the XAI field + few words about the author of this article.</li>
<li>Today we are talking about Shapley values, so the article of the day will be the 2017 SHAP method article.</li>
<li>It will be about the paper <a href="https://papers.nips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html">A Unified Approach to Interpreting Model Predictions</a></li>
</ul>
<p>
<img src="images/shap_abstract.png" width="100%">
</p>
</section>
<section id="shap-paper-in-numbers" class="slide level2">
<h2>SHAP paper in numbers</h2>
<ul>
<li>This article is really exceptional, it will soon exceed 10,000 citations which is an amazing achievement.</li>
<li>The article has several strong points, which we will talk about later today, one of which is the available software that allows you to easily use the described method</li>
<li>This software is a shap library, which on GitHub has skyrocketing numbers of stars and downloads</li>
</ul>
<p>
<img src="images/shap_popular2.png" width="100%">
</p>
<p>
<img src="images/shap_popular3.png" width="100%">
</p>
</section>
<section id="why-shap" class="slide level2">
<h2>Why SHAP?</h2>
<ul>
<li>Shapley values are currently the most popular technique for model explanations (almost in each category: local, global, model agnostic, model specific…)</li>
<li>if you remember only one method after this course, let it be the SHAP</li>
<li>It has more than five years of development. In the list of major XAI methods, you can also find its various extensions like ShapleyFlow or ASV (more about them later)</li>
<li>figures below are from the paper <a href="https://link.springer.com/chapter/10.1007/978-3-031-04083-2_2">Explainable AI Methods - A Brief Overview</a></li>
</ul>
<p>
<img src="images/shap_intro1.png" width="100%">
</p>
<p>
<img src="images/shap_intro2.png" width="100%">
</p>
</section>
<section id="xai-pyramid" class="slide level2">
<h2>XAI pyramid</h2>
<ul>
<li>We will use an XAI pyramid to present new methods during this course.</li>
<li>Today we will mainly talk about the method of local explanations - Shapley values, which for a single observation determines the importance of variables.</li>
</ul>
<p>
<img src="images/xai_piramide_shap1.png" width="100%">
</p>
<ul>
<li>This is one of the three fundamental methods of explaining the behaviour of predictive models.</li>
<li>The following three panels introduce these three concepts; we will return to them in one week and two weeks.</li>
<li>SHAP corresponds to panel C. We try to explain the behaviour of the model by decomposing the distance between this particular prediction and the average prediction of the model.</li>
</ul>
<p>
<img src="images/xai_piramide_shap2.png" width="100%">
</p>
</section></section>
<section>
<section id="shapley-values" class="title-slide slide level1 center">
<h1>Shapley values</h1>

</section>
<section id="notation" class="slide level2">
<h2>Notation</h2>
<ul>
<li>We have set of <span class="math inline">\(P = \{1, ..., p\}\)</span> players</li>
<li>For each coalition, i.e.&nbsp;subset <span class="math inline">\(S \subseteq P\)</span> we can calculate the payout <span class="math inline">\(v(S)\)</span> and <span class="math inline">\(v(\{\varnothing\}) = 0\)</span></li>
<li>We want to fairly distribute the payout <span class="math inline">\(v(P)\)</span></li>
<li>Optimal attribution for player <span class="math inline">\(i\in P\)</span> will be denoted as <span class="math inline">\(\phi_i\)</span></li>
</ul>
</section>
<section id="motivational-example-13" class="slide level2">
<h2>Motivational example 1/3</h2>
<p>How to divide the reward?</p>
<ul>
<li>Three parties A, B and C took part in the election.</li>
<li>As a result of the election, parties A and B each have 49% representation in the parliament and party C has 2% representation.</li>
<li>Let’s assume that A and C formed a government.</li>
<li>How to fairly divide the prize (ministries)?</li>
<li>What share of the prize should party C have?</li>
</ul>
<p>Note that any two parties can form a government. In that case, should the prize for C be equal to or less than that for A?</p>
<p>
<img src="images/shap_v_01.png" width="100%">
</p>
</section>
<section id="motivational-example-23" class="slide level2">
<h2>Motivational example 2/3</h2>
<p>Students A, B and C carry out a project together. With this payoff table, determine what portion of the award each student should get.</p>
<p>
<img src="images/shap_v_02.png" width="100%">
</p>
</section>
<section id="motivational-example-23-cont." class="slide level2">
<h2>Motivational example 2/3 cont.</h2>
<p>Students A, B and C carry out a project together. With this payoff table, determine what portion of the award each student should get.</p>
<p>
<img src="images/shap_v_03.png" width="100%">
</p>
</section>
<section id="motivational-example-33" class="slide level2">
<h2>Motivational example 3/3</h2>
<p>Students A, B and C carry out a project together. With this payoff table, determine what portion of the award each student should get.</p>
<p>
<img src="images/shap_v_04.png" width="100%">
</p>
</section>
<section id="motivational-example-33-cont." class="slide level2">
<h2>Motivational example 3/3 cont.</h2>
<p>Students A, B and C carry out a project together. With this payoff table, determine what portion of the award each student should get.</p>
<p>
<img src="images/shap_v_05.png" width="100%">
</p>
</section>
<section id="required-properties-of-fair-payout" class="slide level2">
<h2>Required properties of fair payout</h2>
<p>One can define various desirable properties of fair reward distribution. The following seem to be natural (or at least they were for Lord Shapley).</p>
<ul>
<li><strong>Efficiency</strong>: all contributions sum up to the final reward</li>
</ul>
<p><span class="math display">\[
\sum_j \phi_j = v(P)
\]</span></p>
<ul>
<li><strong>Symmetry</strong>: if players <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> contributed in the same way to each coalition then they get the same reward</li>
</ul>
<p><span class="math display">\[
\forall_S v(S \cup \{i\}) = v(S \cup \{j\})     \Rightarrow \phi_i = \phi_j
\]</span></p>
<ul>
<li><strong>Dummy</strong>: if player <span class="math inline">\(i\)</span> does not contribute then its reward is <span class="math inline">\(0\)</span></li>
</ul>
<p><span class="math display">\[
\forall_S v(S \cup \{i\}) = v(S)    \Rightarrow \phi_i = 0
\]</span></p>
<ul>
<li><strong>Additivity</strong>: reward in sum of games <span class="math inline">\(v_1\)</span> and <span class="math inline">\(v_2\)</span> is sum of rewards</li>
</ul>
<p><span class="math display">\[
\forall_S v(S) = v_1(S) + v_2(S)    \Rightarrow \phi_i = \phi_{1,i} + \phi_{2,i}
\]</span></p>
</section>
<section id="shapley-values-via-permutations" class="slide level2">
<h2>Shapley values (via permutations)</h2>
<ul>
<li>Fair reward sharing strategy for player <span class="math inline">\(j\in P\)</span> will be denoted as <span class="math inline">\(\phi_j\)</span>. Surprise, these are Shapley values.</li>
<li>Note that added value of player <span class="math inline">\(j\)</span> to coalition <span class="math inline">\(S\)</span> is <span class="math inline">\(v(S \cup \{j\}) - v(S)\)</span></li>
<li>Shapley values are defined as</li>
</ul>
<p><span class="math display">\[
\phi_j = \frac{1}{|P|!} \sum_{\pi \in \Pi} (v(S_j^\pi \cup \{j\}) - v(S_j^\pi))
\]</span></p>
<p>where <span class="math inline">\(\Pi\)</span> is a set of all possible permutations of players <span class="math inline">\(P\)</span> while <span class="math inline">\(S_j^\pi\)</span> is a set of players that are before player <span class="math inline">\(j\)</span> in permutation <span class="math inline">\(\pi\)</span>.</p>
<ul>
<li>Instead of trying all <span class="math inline">\(\Pi\)</span> permutations one can use only <span class="math inline">\(B\)</span> random permutations to estimate <span class="math inline">\(\phi_j\)</span></li>
</ul>
<p><span class="math display">\[
\hat\phi_j = \frac{1}{|B|} \sum_{\pi \in B} (v(S_j^\pi \cup \{j\}) - v(S_j^\pi))
\]</span></p>
</section>
<section id="shapley-values-via-subsets" class="slide level2">
<h2>Shapley values (via subsets)</h2>
<p>
<img src="images/shap_order.png" width="100%">
</p>
<ul>
<li>Once you have a given set <span class="math inline">\(S_j^\pi\)</span> of players that are before <span class="math inline">\(j\)</span> in a permutation <span class="math inline">\(\pi\)</span>, then the added value of <span class="math inline">\(j\)</span> is the same for all permutations that starts with <span class="math inline">\(S_j^\pi\)</span>. There is <span class="math inline">\((|P| - |S_j^\pi| - 1)!\)</span> of such permutations.</li>
<li>Also the order of players in <span class="math inline">\(S_j^\pi\)</span> does not matter as the added value of <span class="math inline">\(j\)</span> is the same for all permutations of <span class="math inline">\(S_j^\pi\)</span>. There is <span class="math inline">\(|S_j^\pi|!\)</span> of such orders.</li>
<li>Formula for Shapley values can be rewritten in a following way</li>
</ul>
<p><span class="math display">\[
\phi_j = \sum_{S \subseteq P / \{j\}}  \frac{|S|! (|P| - |S| - 1)!}{|P|!} (v(S \cup \{j\}) - v(S))
\]</span></p>
<ul>
<li>The advantage is summing over subsets, of which there are <span class="math inline">\(2^p\)</span> instead of permutations, of which there are <span class="math inline">\(p!\)</span>.</li>
</ul>
</section>
<section id="motivational-example-33-solution" class="slide level2">
<h2>Motivational example 3/3 solution</h2>
<p>Students A, B and C carry out a project together. With this payoff table, determine what portion of the award each student should get.</p>
<p>
<img src="images/shap_v_05.png" width="100%">
</p>
<ul>
<li>Now we can calculate the Shapley values and they will be a fair distribution of the reward between students A, B and C</li>
</ul>
<p><span class="math display">\[
\phi_{A} = \frac{1}{6} (10*2 + 20 + 10 + 40*2) = 21 \frac 23
\]</span></p>
<p><span class="math display">\[
\phi_{B} = \frac{1}{6} (30*2 + 40 + 10 + 40*2) = 31 \frac 23
\]</span></p>
<p><span class="math display">\[
\phi_{C} = \frac{1}{6} (50*2 + 50 + 30 + 50*2) = 46 \frac 23
\]</span></p>
</section></section>
<section>
<section id="shapley-values-for-machine-learning-models" class="title-slide slide level1 center">
<h1>Shapley values for Machine Learning Models</h1>

</section>
<section id="definitions" class="slide level2">
<h2>Definitions</h2>
<ul>
<li><p>Let’s start with local explanations, focused on single point <span class="math inline">\(x\)</span> and the model prediction <span class="math inline">\(f(x)\)</span>.</p></li>
<li><p>Now instead of players, you can think about variables. We will distribute a reward between variables to recognize their contribution to the model prediction <span class="math inline">\(f(x)\)</span>.</p></li>
<li><p>Reward to be distributed among players:</p></li>
</ul>
<p><span class="math display">\[
f(x) - E f(x)
\]</span></p>
<div class="fragment">
<ul>
<li>Payoff value function for coalition <span class="math inline">\(S\)</span></li>
</ul>
<p><span class="math display">\[
v(S) = f_S(x_S) - E f(x)
\]</span></p>
<p>where <span class="math inline">\(f_S(x_S)\)</span> is the model prediction maginalized over <span class="math inline">\(P/S\)</span> variables, i.e.</p>
<p><span class="math display">\[
f_S(x_S) = \int_{X_{-S}} f(x_S, X_{-S}) dP(X_{-S})
\]</span></p>
</div>
<div class="fragment">
<ul>
<li>Shapley values via permutations</li>
</ul>
<p><span class="math display">\[
\phi_j = \frac{1}{|P|!} \sum_{\pi \in \Pi} v(S_j^\pi \cup \{j\}) - v(S_j^\pi)
\]</span></p>
<p><strong>Note:</strong> <span class="math inline">\(|P|!\)</span> grows quite fast. <span class="math inline">\(10! = 3 628 800\)</span>. Good news: instead of checking all permutations, one can focus on random <span class="math inline">\(M\)</span> permutations. Also calculation of <span class="math inline">\(f_S(x_S)\)</span> may be computationally heavy for large datasets. But it may be approximated on a subset of observations.</p>
</div>
</section>
<section id="how-to-understand-the-value-function" class="slide level2">
<h2>How to understand the value function</h2>
<ul>
<li>Let’s take a look at how the value function works for a set S of players using the Titanic data example and an explanation for the observations age=8, class=1st, fare=72, ….</li>
<li>Let’s consider the process of conditioning the distribution of data on consecutive variables. In the figure below, we start the prediction distribution for all data, this corresponds to a coalition without players.</li>
<li>Then we add the player <code>age</code>, which means conditioning the data with the condition <code>age=8</code>. Implementation-wise, assuming the independence of the variables, this would correspond to replacing the age value in each observation with the value 8.</li>
<li>Next, we add the class variable to the coalition, which means further conditioning the data with the condition <code>class=1st</code>. In the next step, we add fare to the coalition, and so on.</li>
<li>In the last step, once all the players are in the coalition, that is, all the variables, the model’s predictions will reduce to a single point <span class="math inline">\(f(x)\)</span></li>
</ul>
<p>
<img src="images/xai_bd_1.png" width="100%">
</p>
<ul>
<li>In fact, we are not interested in the distributions of conditional predictions, only in the expected value of these distributions. This is what our value function is.</li>
</ul>
<p>
<img src="images/xai_bd_2.png" width="100%">
</p>
<ul>
<li>The added value of variable <span class="math inline">\(j\)</span> when added to the coalition <span class="math inline">\(S\)</span> is the change in expected value. In the example below, adding the <code>class</code> variable to a coalition with the <code>age</code> variable increases the reward by <span class="math inline">\(0.086\)</span>.</li>
</ul>
<p>
<img src="images/xai_bd_3.png" width="100%">
</p>
</section>
<section id="average-of-conditional-contributions" class="slide level2">
<h2>Average of conditional contributions</h2>
<ul>
<li>The Shapley value is the average after all (or a large number) of the orders in which variables are added to the coalition.</li>
<li>For diagnostic purposes, on graphs, we can also highlight the distribution of added values for different coalitions to get information on how much the effect of a given variable is additive, i.e.&nbsp;leads to the same added value regardless of the previous composition of the coalition.</li>
</ul>
<p>
<img src="images/xai_bd_4.png" width="100%">
</p>
<ul>
<li>Order matters. For a model that allows interactions, it is easy to find an example of a non-additive effect of a variable. How to explain the different effects of the age variable in the figure below?</li>
</ul>
<p>
<img src="images/xai_bd_5.png" width="100%">
</p>
</section>
<section id="shap-values" class="slide level2">
<h2>SHAP values</h2>
<p><span class="math display">\[
\phi_j = \frac{1}{|P|!} \sum_{\pi \in \Pi} v(S_j^\pi \cup \{j\}) - v(S_j^\pi)
\]</span></p>
<ul>
<li>The <span class="math inline">\(v(S \cup \{j\}) - v(S)\)</span> may be approximated with <span class="math inline">\(\hat f_{S \cup \{j\}}(x^*) - \hat f_S(x^*)\)</span> where</li>
</ul>
<p><span class="math display">\[
\hat f_S(x^*) = \sum_{i=1}^N f(x^*_S, x^i_{-S})
\]</span></p>
<ul>
<li>The exact calculation of Shapley values leads to the formula</li>
</ul>
<p><span class="math display">\[
\phi_j(x^*) = \frac{1}{N |P|!} \sum_{\pi \in \Pi} \sum_{i=1}^{N}  f(x^*_{S^\pi \cup \{j\}}, x^i_{-S^\pi \cup \{j\}}) - f(x^*_{S^\pi}, x^i_{-S^\pi})
\]</span></p>
<ul>
<li><strong>Note:</strong> For estimation, one can use an only subset of permutations from <span class="math inline">\(\Pi\)</span> and a subset of observations <span class="math inline">\(\{1, ..., N\}\)</span>.</li>
</ul>
</section>
<section id="kernel-shap" class="slide level2">
<h2>Kernel SHAP</h2>
<ul>
<li>Accurate calculation of Shapley values is a very time-consuming task.</li>
<li>The Kernel-SHAP method makes it possible to estimate these values at a lower computational cost - and thus faster.</li>
<li>You can think of it as an adaptation of the LIME method. The explanation, too, is a linear model approximation of the model in an interpretable feature space.</li>
<li>The interpretable variable space is a binary space describing whether a variable enters a coalition or not. If it enters the coalition then we use the value of this variable from the observation being explained. If it doesn’t then we sample a value from the dataset in its place.</li>
<li>We compute Shapley values by weighted linear regression using an interpretable representation of the variables as input. Linear regression coefficients are estimates of Shapley values.</li>
</ul>
<p>
<img src="images/shap_kernel.png" width="100%">
</p>
</section>
<section id="tree-shap" class="slide level2">
<h2>Tree SHAP</h2>
<p>Trees have nice structure, it makes them easier to analyse with Shapley values.</p>
<p>For a model that is a weighted sum of trees (bagging, boosting, random forest) the Shapley values for the model are weighted Shapley values for each tree.</p>
<p>Let’s consider a brute force algorithm for a single tree (processing from leaves to the root):</p>
<ul>
<li>for a leaf, it returns the value in the leaf,</li>
<li>for a node with a variable from S it returns the value of a left or right node given the variable’s value,</li>
<li>for a node without a variable from S it returns the weighted average of the left and right nodes.</li>
</ul>
<p>The brute force algorithm has complexity <span class="math inline">\(O(2^m)\)</span></p>
<p>but one can go down to <span class="math inline">\(O(XTLD^2) = O(TLD \cdot XD)\)</span></p>
</section>
<section id="tree-shap---an-example" class="slide level2">
<h2>Tree SHAP - an example</h2>
<ul>
<li>Let’s calculate <span class="math inline">\(val(S)\)</span> for <code>x = (age: 5, fare:20, sibsp:2)</code>.</li>
</ul>
<p>
<img src="images/xai_bd_6.png" width="100%">
</p>
<ul>
<li>where</li>
</ul>
<p><span class="math display">\[
v(S) = \int_{X_{-S}} f(x_S, X_{-S}) dP(X_{-S}) - E f(x)
\]</span></p>
</section>
<section id="from-local-to-global-feature-importance" class="slide level2">
<h2>From local to global – Feature importance</h2>
<ul>
<li>The SHAP method gives local explanations, i.e.&nbsp;explanations for each single observation. But we can convert them to global explanations by aggregating the explanations for individual observations.</li>
<li>For example, we can assess the validity of a variable by counting the average modulus of SHAP explanations.</li>
<li>Such a measure of the importance of variables does not depend on the model structure and can be used to compare models.</li>
<li>Below is an example for the model trained for Titanic data</li>
</ul>
<p>
<img src="images/shap_global_3.png" width="100%">
</p>
</section>
<section id="from-local-to-global-summary-plot" class="slide level2">
<h2>From local to global – Summary plot</h2>
<ul>
<li>One of the most useful statistics is a plot summarizing the distribution of Shapley values for the data for each variable.</li>
<li>On the OX axis are presented the Shapley values, in the rows are the variables. The color indicates whether an observation had a high or low value in that variable.</li>
<li>From the graph you can read which variables are important (they have a large spread of points)</li>
<li>You can read what is the relationship between the variable and the Shapley value, whether the color has a monotonic gradation or there are some dependencies</li>
<li>You can read the distribution of Shapley values</li>
</ul>
<p>
<img src="images/shap_global_2.png" width="100%">
</p>
</section>
<section id="from-local-to-global-dependence-plot" class="slide level2">
<h2>From local to global – Dependence plot</h2>
<ul>
<li>If we plot the Shapley values as functions of the value of the original variable, it is possible to see what kind of relationship exists between this variable and the average result.</li>
<li>This type of plots allows you to choose the transformations of the variable, and better understand the relationship between this variable and the result of the model</li>
</ul>
<p>
<img src="images/shap_global_4.png" width="100%">
</p>
<ul>
<li>We can additionally color the graph depending on one more variable (in the example below, it is gender) to see if an interaction is present in the model. In this case, the attributes of the model will depend on the value of this additional variable.</li>
</ul>
<p>
<img src="images/shap_global_5.png" width="100%">
</p>
</section></section>
<section id="take-home-message" class="title-slide slide level1 center">
<h1>Take-home message</h1>
<ul>
<li>Shapley’s values are based on a concept with roots in <strong>cooperative game theory</strong></li>
<li>We treat <strong>variables as players</strong> who, in coalitions, influence the prediction of the model</li>
<li>Shapley’s values result in <strong>additive decomposition of the reward</strong> which is <span class="math inline">\(f(x) - E f(x)\)</span></li>
<li>Shapley’s values can be calculated in a model-agnostic fashion, but for some models (linear models, tree-based models) there are more efficient ways to estimate such values</li>
<li><strong>From local to global</strong>. Based on local explanations, global explanations can be constructed</li>
<li>In the explanation, <strong>each variable has attributions</strong>. For models with many variables, this can be a problem</li>
</ul>
</section>

<section id="code-examples" class="title-slide slide level1 center">
<h1>Code-examples</h1>
<ul>
<li>See <a href="https://github.com/mim-uw/eXplainableMachineLearning-2023/Materials">Materials at GitHub</a></li>
</ul>
<p>
<img src="images/shap_code.png" width="100%">
</p>
<p><img src="images/XAI.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>eXplainable AI – Shapley values – MIM UW – 2022</p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="02_shap_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="02_shap_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="02_shap_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="02_shap_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="02_shap_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="02_shap_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="02_shap_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="02_shap_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="02_shap_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="02_shap_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="02_shap_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        function fireSlideChanged(previousSlide, currentSlide) {

          // dispatch for htmlwidgets
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for reveal
        if (window.Reveal) {
          window.Reveal.addEventListener("slidechanged", function(event) {
            fireSlideChanged(event.previousSlide, event.currentSlide);
          });
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        setTimeout(function() {
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          let href = ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const cites = ref.parentNode.getAttribute('data-cites').split(' ');
        tippyHover(ref, function() {
          var popup = window.document.createElement('div');
          cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    });
    </script>
    

</body></html>